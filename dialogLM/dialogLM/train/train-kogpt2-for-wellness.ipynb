{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NCpnYj2bfXvG"},"source":["# Wellness 심리 상담 데이터에 대한 KoGPT2 학습"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EN1oD-YEfukE"},"source":["## 1.Google Drive 연동\n","- 모델 파일과 학습 데이터가 저장 되어있는 구글 드라이브의 디렉토리와 Colab을 연동.  \n","- 좌측상단 메뉴에서 런타임-> 런타임 유형 변경 -> 하드웨어 가속기 -> GPU 선택 후 저장"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7TlLDiAJf0Zz"},"source":["### 1.1 GPU 연동 확인"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"colab_type":"code","executionInfo":{"elapsed":2445,"status":"ok","timestamp":1594261266492,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"Q1qPeOGVfkb_","outputId":"b76262a9-2a87-4c7c-8a1f-ad6c7c437e0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Active code page: 65001\n"]},{"name":"stderr","output_type":"stream","text":["'nvidia-smi' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9tW2_JPaf79o"},"source":["### 1.2 Google Drive 연동\n","아래 코드를 실행후 나오는 URL을 클릭하여 나오는 인증 코드 입력"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":2439,"status":"ok","timestamp":1594261266493,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"7voF7JHtf4J5","outputId":"56a91f80-8b21-425f-81c9-64c3c03ec6b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"T4MqQlXugAdI"},"source":["**Colab 디렉토리 아래 dialogLM 경로 확인**\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"colab_type":"code","executionInfo":{"elapsed":4248,"status":"ok","timestamp":1594261268309,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"mdqgpGkLgGoc","outputId":"72d4541c-d92a-48f5-d4d9-7fd9528ec15a"},"outputs":[{"name":"stdout","output_type":"stream","text":[" BERT_X\t\t      'fastprogress example.ipynb'    NarrativeKoGPT2\n"," Data\t\t       KorQuAD-beginner\t\t      ReforBERT\n"," dialogLM\t       korquad-finetuing.ipynb\n"," EnlipleBERTFintuing   korquad-finetuing-ver2.ipynb\n"]}],"source":["!ls drive/'My Drive'/'Colab Notebooks'/"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wA36dTxFgMA8"},"source":["**필요 패키지 설치**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"colab_type":"code","executionInfo":{"elapsed":7280,"status":"ok","timestamp":1594261271348,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"OdbnMf8NjSHN","outputId":"9735dae4-697d-4dc1-ced9-f2fa7d73a581"},"outputs":[{"name":"stdout","output_type":"stream","text":["Active code page: 65001Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","s2s-ft 0.0.1 requires transformers<=2.10.0, but you have transformers 3.0.2 which is incompatible.\n","\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["\n","Collecting kobert-transformers==0.4.1\n","  Using cached kobert_transformers-0.4.1-py3-none-any.whl (12 kB)\n","Collecting kogpt2-transformers==0.3.0\n","  Using cached kogpt2_transformers-0.3.0-py3-none-any.whl (4.6 kB)\n","Collecting transformers==3.0.2\n","  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n","Requirement already satisfied: torch in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from -r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (2.1.2)\n","Collecting tokenizers==0.8.1rc1\n","  Downloading tokenizers-0.8.1rc1-cp38-cp38-win_amd64.whl (1.9 MB)\n","     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n","      --------------------------------------- 0.0/1.9 MB 640.0 kB/s eta 0:00:03\n","     ------------ --------------------------- 0.6/1.9 MB 5.9 MB/s eta 0:00:01\n","     ---------------------------------------  1.9/1.9 MB 13.1 MB/s eta 0:00:01\n","     ---------------------------------------- 1.9/1.9 MB 11.9 MB/s eta 0:00:00\n","Collecting kss\n","  Using cached kss-4.5.4-py3-none-any.whl\n","Collecting flask\n","  Using cached flask-3.0.0-py3-none-any.whl (99 kB)\n","Collecting flask_restful\n","  Using cached Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: tqdm>=4.27 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (4.66.1)\n","Requirement already satisfied: requests in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (2.31.0)\n","Requirement already satisfied: numpy in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (1.24.4)\n","Requirement already satisfied: filelock in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (3.13.1)\n","Requirement already satisfied: packaging in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (23.2)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (2023.12.25)\n","Requirement already satisfied: sentencepiece!=0.1.92 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (0.1.99)\n","Requirement already satisfied: sacremoses in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (0.1.1)\n","Requirement already satisfied: jinja2 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (3.1.2)\n","Requirement already satisfied: typing-extensions in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (4.9.0)\n","Requirement already satisfied: networkx in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (3.1)\n","Requirement already satisfied: fsspec in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (2023.12.2)\n","Requirement already satisfied: sympy in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (1.12)\n","Collecting pecab\n","  Using cached pecab-1.0.8-py3-none-any.whl\n","Collecting emoji==1.2.0\n","  Using cached emoji-1.2.0-py3-none-any.whl (131 kB)\n","Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from flask->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 7)) (7.0.1)\n","Collecting blinker>=1.6.2\n","  Using cached blinker-1.7.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: click>=8.1.3 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from flask->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 7)) (8.1.7)\n","Collecting Werkzeug>=3.0.0\n","  Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n","Collecting itsdangerous>=2.1.2\n","  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n","Collecting pytz\n","  Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n","Requirement already satisfied: six>=1.3.0 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from flask_restful->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 8)) (1.16.0)\n","Collecting aniso8601>=0.82\n","  Using cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n","Requirement already satisfied: colorama in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from click>=8.1.3->flask->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 7)) (0.4.6)\n","Requirement already satisfied: zipp>=0.5 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from importlib-metadata>=3.6.0->flask->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 7)) (3.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from jinja2->torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (2.1.3)\n","Collecting pytest\n","  Using cached pytest-7.4.3-py3-none-any.whl (325 kB)\n","Collecting pyarrow\n","  Downloading pyarrow-14.0.2-cp38-cp38-win_amd64.whl (24.6 MB)\n","     ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n","     -- ------------------------------------- 1.7/24.6 MB 35.7 MB/s eta 0:00:01\n","     ----- ---------------------------------- 3.6/24.6 MB 38.1 MB/s eta 0:00:01\n","     --------- ------------------------------ 5.6/24.6 MB 40.2 MB/s eta 0:00:01\n","     ----------- ---------------------------- 7.4/24.6 MB 39.3 MB/s eta 0:00:01\n","     -------------- ------------------------- 8.9/24.6 MB 37.9 MB/s eta 0:00:01\n","     ----------------- --------------------- 11.1/24.6 MB 38.5 MB/s eta 0:00:01\n","     -------------------- ------------------ 12.9/24.6 MB 38.5 MB/s eta 0:00:01\n","     ----------------------- --------------- 14.5/24.6 MB 38.5 MB/s eta 0:00:01\n","     -------------------------- ------------ 16.5/24.6 MB 38.5 MB/s eta 0:00:01\n","     ---------------------------- ---------- 18.2/24.6 MB 38.5 MB/s eta 0:00:01\n","     ------------------------------- ------- 19.8/24.6 MB 36.4 MB/s eta 0:00:01\n","     ---------------------------------- ---- 21.5/24.6 MB 34.4 MB/s eta 0:00:01\n","     ------------------------------------ -- 23.1/24.6 MB 36.4 MB/s eta 0:00:01\n","     --------------------------------------  24.6/24.6 MB 34.4 MB/s eta 0:00:01\n","     --------------------------------------- 24.6/24.6 MB 28.4 MB/s eta 0:00:00\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from requests->transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (2023.11.17)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from requests->transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from requests->transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (1.26.18)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from requests->transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (3.3.2)\n","Requirement already satisfied: joblib in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from sacremoses->transformers==3.0.2->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 3)) (1.3.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages (from sympy->torch->-r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt (line 4)) (1.3.0)\n","Collecting pluggy<2.0,>=0.12\n","  Using cached pluggy-1.3.0-py3-none-any.whl (18 kB)\n","Collecting tomli>=1.0.0\n","  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n","Collecting iniconfig\n","  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n","Collecting exceptiongroup>=1.0.0rc8\n","  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n","Installing collected packages: tokenizers, pytz, emoji, aniso8601, Werkzeug, tomli, pyarrow, pluggy, itsdangerous, iniconfig, exceptiongroup, blinker, pytest, flask, transformers, pecab, flask_restful, kss, kogpt2-transformers, kobert-transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.7.0\n","    Uninstalling tokenizers-0.7.0:\n","      Successfully uninstalled tokenizers-0.7.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 2.10.0\n","    Uninstalling transformers-2.10.0:\n","      Successfully uninstalled transformers-2.10.0\n","Successfully installed Werkzeug-3.0.1 aniso8601-9.0.1 blinker-1.7.0 emoji-1.2.0 exceptiongroup-1.2.0 flask-3.0.0 flask_restful-0.3.10 iniconfig-2.0.0 itsdangerous-2.1.2 kobert-transformers-0.4.1 kogpt2-transformers-0.3.0 kss-4.5.4 pecab-1.0.8 pluggy-1.3.0 pyarrow-14.0.2 pytest-7.4.3 pytz-2023.3.post1 tokenizers-0.8.1rc1 tomli-2.0.1 transformers-3.0.2\n"]}],"source":["# %pip install -r C:\\sqlite\\mysql\\code\\AI\\FINAL_project\\dialogLM\\dialogLM\\requirements.txt\n","!pip install kogpt2-transformers\n","!pip install kobert-transformers\n","!pip install torch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install tokenizers\n","!pip install transformers"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i51bCZyCjZzy"},"source":["## KoGPT-2 Training"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UFSAkW6MkZb7"},"source":["**Path 추가**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KrFfFlV8jfcg"},"source":["### 2.1 import package"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"C:\\\\sqlite\\\\mysql\\\\code\\\\AI\\\\FINAL_project\\\\dialogLM\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{},"colab_type":"code","executionInfo":{"elapsed":9230,"status":"ok","timestamp":1594261273309,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"88ApclaNjVvh"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","from torch.utils.data import dataloader\n","from dialogLM.dataloader.wellness import WellnessAutoRegressiveDataset\n","from dialogLM.model.kogpt2 import DialogKoGPT2"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":9227,"status":"ok","timestamp":1594261273310,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"iHvrtMJaoV_Z","outputId":"b08392b9-6cee-453c-bf98-408225170434"},"outputs":[{"data":{"text/plain":["False"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mZuWyjJEjxsF"},"source":["### KoGPT2 Training for Wellness dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102},"colab_type":"code","executionInfo":{"elapsed":15980388,"status":"ok","timestamp":1594277322997,"user":{"displayName":"김성환","photoUrl":"","userId":"17497395371430681608"},"user_tz":-540},"id":"Y9vwUZQ9j0DN","outputId":"2307aa01-3143-41c7-d80e-1517989f542f"},"outputs":[{"name":"stderr","output_type":"stream","text":["model.safetensors: 100%|██████████| 510M/510M [00:13<00:00, 37.1MB/s] \n","c:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--taeminlee--kogpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Train(0):   4%|▍         | 94/2360 [14:50<5:57:55,  9.48s/it, Loss: 3.544 (3.694)]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m shift_labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fct(shift_logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, shift_logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), shift_labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[1;32mc:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\sqlite\\mysql\\code\\mynewenv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["root_path='C:\\\\sqlite\\\\mysql\\\\code\\\\AI\\\\FINAL_project\\\\dialogLM\\\\dialogLM\\\\dataloader'\n","data_path = f\"{root_path}\\\\wellness_dialog_for_autoregressive_train.txt\"\n","checkpoint_path =f\"{root_path}\\\\checkpoint\"\n","save_ckpt_path = f\"{checkpoint_path}\\\\kogpt2-wellnesee-auto-regressive.pth\"\n","\n","n_epoch = 5         # Num of Epoch\n","batch_size = 2      # 배치 사이즈\n","ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(ctx)\n","save_step = 100 # 학습 저장 주기\n","learning_rate = 5e-5  # Learning Rate\n","\n","dataset= WellnessAutoRegressiveDataset(data_path)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","model = DialogKoGPT2()\n","model.to(device)\n","\n","\n","loss_fct = torch.nn.CrossEntropyLoss(ignore_index=3)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","losses =[]\n","for epoch in range(n_epoch):\n","    count = 0\n","    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n","        for i, data in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            data = torch.stack(data)  # list of Tensor로 구성되어 있기 때문에 list를 stack을 통해 변환해준다.\n","            data = data.transpose(1, 0)\n","            data= data.to(ctx)\n","\n","            outputs = model(data, labels=data)\n","            _, logits = outputs[:2]\n","\n","            # Shift so that tokens < n predict n\n","            shift_logits = logits[..., :-1, :].contiguous()\n","            shift_labels = data[..., 1:].contiguous()\n","\n","            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            losses.append(loss.item())\n","\n","            # if count % 10 == 0:\n","            #     print('epoch no.{} train no.{}  loss = {}'.format(epoch, count + 1, loss))\n","            if (count > 0 and count % save_step == 0) or (len(data) < batch_size):\n","                torch.save({\n","                    'epoch': epoch,\n","                    'train_no': count,\n","                    'model_state_dict': model.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': loss\n","                }, save_ckpt_path)\n","            count += 1\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Loss: {loss.item():.3f} ({np.mean(losses):.3f})\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO4qrGsvzHebgs/B3yfVyLQ","collapsed_sections":[],"machine_shape":"hm","name":"train-kogpt2-for-wellness.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}
